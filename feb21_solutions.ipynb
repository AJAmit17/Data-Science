{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Web scraping is a technique of extracting specific data from websites automatically using software or tools. It is typically used to extract large volumes of data that would otherwise take a substantial amount of time to collect manually. \n",
    "\n",
    "Web scraping is used for various purposes, including:\n",
    "\n",
    "1. Market research: Companies use web scraping to gather data about their competitors, track price changes, and analyze market trends.\n",
    "\n",
    "2. Academic research: Researchers use web scraping to collect data for academic studies and research projects in various fields like Sociology, Political Science, and Economics.\n",
    "\n",
    "3. Business Intelligence: Business analysts use web scraping to acquire data about consumer trends, market demands, and product prices to make informed business decisions.\n",
    "\n",
    "Three areas where web scraping is used to get data are:\n",
    "1. E-commerce websites to collect product information and pricing data\n",
    "2. Social media platforms to collect engagement metrics, follower counts, and user-generated content\n",
    "3. Job search platforms to collect job listings and hiring data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "There are several methods used for web scraping. Some of them are:\n",
    "\n",
    "1. BeautifulSoup: This is a Python library that is used for web scraping purposes. It is capable of parsing HTML and XML documents and it provides methods to navigate and search the parsed data.\n",
    "\n",
    "2. Scrapy: This is one of the most widely used Python-based web scraping tools. It provides developers with several features such as easy extraction of data, handling of cookies and sessions, support for multiple concurrent requests, and much more.\n",
    "\n",
    "3. Selenium: This is a web automation tool that can be used for web scraping purposes. It can simulate real user interactions with web pages, such as clicking buttons and filling out forms, to extract data.\n",
    "\n",
    "4. Requests: This is a Python library used to send HTTP requests and handle responses. It can be used to crawl and scrape web pages by making requests to URLs and retrieving the content.\n",
    "\n",
    "5. APIs: Some websites provide APIs that can be used to extract data in a structured format. These APIs can be accessed using programming languages such as Python or JavaScript."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Beautiful Soup is a Python library designed for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree for parsed pages and provides methods to navigate and search the parse tree. \n",
    "\n",
    "It is used because it can handle common parsing tasks easily such as tag, attribute, and text extraction. It's also user-friendly and easy to learn. Beautiful Soup is widely used within the web scraping community because it can handle most of the web scraping needs. Additionally, with Beautiful Soup, web developers can write fewer lines of code and save time while extracting data from web pages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Flask is used in this web scraping project because it provides a simple and efficient way to create a web application that can display the data collected through web scraping. Flask allows us to create a web interface that enables users to interact with the scraped data, provide input parameters for the scraper, display results in web pages, and perform other useful functions. Flask also supports templating engines that enable us to quickly and easily create beautiful and responsive front-end interfaces, making it an ideal choice for creating a web application that uses web scraping. Additionally, Flask allows us to easily deploy the web application to cloud platforms such as Heroku, making it accessible to users across the globe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Elastic Beanstalk is a fully-managed service that makes it easier to deploy and run web applications in the cloud. It allows developers to easily deploy applications without worrying about infrastructure details, such as scaling, load balancing, and monitoring.\n",
    "\n",
    "CodePipeline is a continuous delivery service that is used to automate the release process for software applications. It automates the entire building, testing, and deployment workflow and can integrate with various development tools, such as GitHub and AWS CodeCommit. It allows developers to easily create and manage multiple release pipelines, which can be customized to suit specific project requirements. \n",
    "\n",
    "In this project, Elastic Beanstalk is used to deploy and run the web application, while CodePipeline is used to automate the release process and ensure smooth delivery of updates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
